FROM nvidia/cuda:12.1-runtime-ubuntu22.04

# –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≤–æ –≤—Ä–µ–º—è —Å–±–æ—Ä–∫–∏
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3.10-dev \
    python3-pip \
    python3.10-venv \
    ffmpeg \
    libsndfile1 \
    curl \
    wget \
    git \
    build-essential \
    pkg-config \
    libffi-dev \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–æ–π —Å—Å—ã–ª–∫–∏ –¥–ª—è python
RUN ln -sf /usr/bin/python3.10 /usr/bin/python3 \
    && ln -sf /usr/bin/python3.10 /usr/bin/python

# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ pip
RUN python3 -m pip install --upgrade pip setuptools wheel

# –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–±–æ—á–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
WORKDIR /app

# –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
RUN useradd -m -u 1000 -s /bin/bash appuser \
    && mkdir -p /app/temp /app/logs \
    && chown -R appuser:appuser /app

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch —Å fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π (–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏)
RUN pip3 install --no-cache-dir torch torchvision torchaudio || \
    pip3 install --no-cache-dir torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 || \
    pip3 install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 || \
    pip3 install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ requirements –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
COPY requirements.txt /app/
RUN pip3 install --no-cache-dir -r requirements.txt

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
COPY app.py crypto_utils.py /app/
RUN chown -R appuser:appuser /app

# –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è appuser
USER appuser

# –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper —Å fallback
RUN python3 -c "from faster_whisper import WhisperModel; WhisperModel('base', device='cpu', compute_type='int8')" || \
    python3 -c "print('Whisper model preload skipped - will download on first use')"

# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞
RUN echo '#!/bin/bash\n\
set -e\n\
\n\
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è\n\
if [ -z "$SECRET_ENDPOINT" ] || [ -z "$KEY_DECRYPT" ] || [ -z "$KEY_ENCRYPT" ]; then\n\
    echo "‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è!"\n\
    echo "–¢—Ä–µ–±—É—é—Ç—Å—è: SECRET_ENDPOINT, KEY_DECRYPT, KEY_ENCRYPT"\n\
    exit 1\n\
fi\n\
\n\
# –ü—Ä–æ–≤–µ—Ä–∫–∞ PyTorch –∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤\n\
python3 -c "import torch; print(f\"üî• PyTorch: {torch.__version__}\"); print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\"); print(f\"üì± CUDA devices: {torch.cuda.device_count() if torch.cuda.is_available() else 0}\")" || echo "‚ö†Ô∏è PyTorch check failed"\n\
\n\
# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU (optional)\n\
if command -v nvidia-smi &> /dev/null; then\n\
    echo "üéÆ GPU Information:"\n\
    nvidia-smi --query-gpu=name,memory.total,memory.used --format=csv,noheader,nounits | head -1 || echo "GPU info unavailable"\n\
else\n\
    echo "‚ö†Ô∏è GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU"\n\
fi\n\
\n\
# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π\n\
mkdir -p /app/temp /app/logs\n\
\n\
# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è\n\
echo "üöÄ –ó–∞–ø—É—Å–∫ Stenogramma –Ω–∞ –ø–æ—Ä—Ç—É 8000..."\n\
exec uvicorn app:app --host 0.0.0.0 --port 8000 --workers 1' > /app/entrypoint.sh

RUN chmod +x /app/entrypoint.sh

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8000/endpoint_info || exit 1

# –≠–∫—Å–ø–æ–∑–∏—Ü–∏—è –ø–æ—Ä—Ç–∞
EXPOSE 8000

# –ó–∞–ø—É—Å–∫
ENTRYPOINT ["/app/entrypoint.sh"]