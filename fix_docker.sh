#!/bin/bash

# –°–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å Docker –æ–±—Ä–∞–∑–∞–º–∏ Stenogramma
# –í–µ—Ä—Å–∏—è: 1.0.0

set -e

# –¶–≤–µ—Ç–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

print_info() {
    echo -e "${BLUE}‚ÑπÔ∏è  $1${NC}"
}

print_success() {
    echo -e "${GREEN}‚úÖ $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}‚ö†Ô∏è  $1${NC}"
}

print_error() {
    echo -e "${RED}‚ùå $1${NC}"
}

print_header() {
    echo -e "${BLUE}"
    echo "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
    echo "‚ñà                                                      ‚ñà"
    echo "‚ñà         üîß STENOGRAMMA DOCKER FIX TOOL üîß          ‚ñà"
    echo "‚ñà                                                      ‚ñà"
    echo "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà"
    echo -e "${NC}"
}

# –°–ø–∏—Å–æ–∫ CUDA –æ–±—Ä–∞–∑–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–æ—Ç –Ω–æ–≤—ã—Ö –∫ —Å—Ç–∞—Ä—ã–º)
CUDA_IMAGES=(
    "nvidia/cuda:12.9.0-runtime-ubuntu22.04"
    "nvidia/cuda:12.9.0-base-ubuntu22.04"
    "nvidia/cuda:12.2-runtime-ubuntu22.04"
    "nvidia/cuda:12.1-runtime-ubuntu22.04"
    "nvidia/cuda:12.0-runtime-ubuntu22.04"
    "nvidia/cuda:11.8-runtime-ubuntu22.04"
    "nvidia/cuda:11.7-runtime-ubuntu22.04"
    "ubuntu:22.04"
)

# –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ PyTorch –∏–Ω–¥–µ–∫—Å—ã
declare -A PYTORCH_INDICES=(
    ["nvidia/cuda:12.9.0-runtime-ubuntu22.04"]="cu124"
    ["nvidia/cuda:12.9.0-base-ubuntu22.04"]="cu124"
    ["nvidia/cuda:12.2-runtime-ubuntu22.04"]="cu121"
    ["nvidia/cuda:12.1-runtime-ubuntu22.04"]="cu121"
    ["nvidia/cuda:12.0-runtime-ubuntu22.04"]="cu118"
    ["nvidia/cuda:11.8-runtime-ubuntu22.04"]="cu118"
    ["nvidia/cuda:11.7-runtime-ubuntu22.04"]="cu117"
    ["ubuntu:22.04"]="cpu"
)

check_docker() {
    print_info "–ü—Ä–æ–≤–µ—Ä–∫–∞ Docker..."
    
    if ! command -v docker &> /dev/null; then
        print_error "Docker –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!"
        echo "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Docker: https://docs.docker.com/get-docker/"
        exit 1
    fi
    
    if ! docker info &> /dev/null; then
        print_error "Docker daemon –Ω–µ –∑–∞–ø—É—â–µ–Ω!"
        echo "–ó–∞–ø—É—Å—Ç–∏—Ç–µ Docker daemon"
        exit 1
    fi
    
    print_success "Docker —Ä–∞–±–æ—Ç–∞–µ—Ç"
}

test_base_image() {
    local image=$1
    print_info "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞–∑–∞: $image"
    
    if timeout 30 docker pull "$image" &> /dev/null; then
        print_success "–û–±—Ä–∞–∑ $image –¥–æ—Å—Ç—É–ø–µ–Ω"
        return 0
    else
        print_warning "–û–±—Ä–∞–∑ $image –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
        return 1
    fi
}

find_working_cuda_image() {
    print_info "–ü–æ–∏—Å–∫ —Ä–∞–±–æ—á–µ–≥–æ CUDA –æ–±—Ä–∞–∑–∞..."
    
    for image in "${CUDA_IMAGES[@]}"; do
        if test_base_image "$image"; then
            WORKING_IMAGE="$image"
            PYTORCH_INDEX="${PYTORCH_INDICES[$image]}"
            
            if [[ "$image" == *"nvidia/cuda"* ]]; then
                IS_GPU_IMAGE=true
                print_success "–ù–∞–π–¥–µ–Ω —Ä–∞–±–æ—á–∏–π GPU –æ–±—Ä–∞–∑: $image"
            else
                IS_GPU_IMAGE=false
                print_success "Fallback –Ω–∞ CPU –æ–±—Ä–∞–∑: $image"
            fi
            
            return 0
        fi
    done
    
    print_error "–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ä–∞–±–æ—á–µ–≥–æ –æ–±—Ä–∞–∑–∞!"
    return 1
}

backup_dockerfile() {
    local dockerfile=$1
    if [ -f "$dockerfile" ]; then
        local backup_name="${dockerfile}.backup.$(date +%Y%m%d_%H%M%S)"
        cp "$dockerfile" "$backup_name"
        print_info "–°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: $backup_name"
    fi
}

create_fixed_dockerfile() {
    local dockerfile=$1
    local base_image=$2
    local pytorch_index=$3
    local is_gpu=$4
    
    print_info "–°–æ–∑–¥–∞–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ $dockerfile..."
    
    backup_dockerfile "$dockerfile"
    
    cat > "$dockerfile" << EOF
FROM $base_image

# –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≤–æ –≤—Ä–µ–º—è —Å–±–æ—Ä–∫–∏
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
RUN apt-get update && apt-get install -y \\
    python3.10 \\
    python3.10-dev \\
    python3-pip \\
    python3.10-venv \\
    ffmpeg \\
    libsndfile1 \\
    curl \\
    wget \\
    git \\
    build-essential \\
    pkg-config \\
    libffi-dev \\
    && rm -rf /var/lib/apt/lists/* \\
    && apt-get clean

# –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–æ–π —Å—Å—ã–ª–∫–∏ –¥–ª—è python
RUN ln -sf /usr/bin/python3.10 /usr/bin/python3 \\
    && ln -sf /usr/bin/python3.10 /usr/bin/python

# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ pip
RUN python3 -m pip install --upgrade pip setuptools wheel

# –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–±–æ—á–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
WORKDIR /app

# –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
RUN useradd -m -u 1000 -s /bin/bash appuser \\
    && mkdir -p /app/temp /app/logs \\
    && chown -R appuser:appuser /app

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ requirements –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ Python –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
COPY requirements.txt /app/
EOF

    if [ "$pytorch_index" = "cpu" ]; then
        cat >> "$dockerfile" << EOF
RUN pip3 install --no-cache-dir --upgrade pip \\
    && pip3 install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu \\
    && pip3 install --no-cache-dir -r requirements.txt
EOF
    else
        cat >> "$dockerfile" << EOF
RUN pip3 install --no-cache-dir --upgrade pip \\
    && pip3 install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/$pytorch_index \\
    && pip3 install --no-cache-dir -r requirements.txt
EOF
    fi

    cat >> "$dockerfile" << EOF

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
COPY app.py crypto_utils.py /app/
RUN chown -R appuser:appuser /app

# –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è appuser
USER appuser

# –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper
RUN python3 -c "from faster_whisper import WhisperModel; WhisperModel('large-v3', device='cpu', compute_type='int8')" || true

# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞
RUN echo '#!/bin/bash\\n\\
set -e\\n\\
\\n\\
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è\\n\\
if [ -z "\$SECRET_ENDPOINT" ] || [ -z "\$KEY_DECRYPT" ] || [ -z "\$KEY_ENCRYPT" ]; then\\n\\
    echo "‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è!"\\n\\
    echo "–¢—Ä–µ–±—É—é—Ç—Å—è: SECRET_ENDPOINT, KEY_DECRYPT, KEY_ENCRYPT"\\n\\
    exit 1\\n\\
fi\\n\\
\\n\\
EOF

    if [ "$is_gpu" = true ]; then
        cat >> "$dockerfile" << EOF
# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU\\n\\
if command -v nvidia-smi &> /dev/null; then\\n\\
    echo "üéÆ GPU Information:"\\n\\
    nvidia-smi --query-gpu=name,memory.total,memory.used --format=csv,noheader,nounits | head -1 || echo "GPU info unavailable"\\n\\
else\\n\\
    echo "‚ö†Ô∏è  GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU"\\n\\
fi\\n\\
EOF
    else
        cat >> "$dockerfile" << EOF
echo "üñ•Ô∏è  –ó–∞–ø—É—Å–∫ –≤ CPU —Ä–µ–∂–∏–º–µ"\\n\\
EOF
    fi

    cat >> "$dockerfile" << EOF
\\n\\
# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π\\n\\
mkdir -p /app/temp /app/logs\\n\\
\\n\\
# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è\\n\\
echo "üöÄ –ó–∞–ø—É—Å–∫ Stenogramma –Ω–∞ –ø–æ—Ä—Ç—É 8000..."\\n\\
exec uvicorn app:app --host 0.0.0.0 --port 8000 --workers 1' > /app/entrypoint.sh

RUN chmod +x /app/entrypoint.sh

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \\
    CMD curl -f http://localhost:8000/endpoint_info || exit 1

# –≠–∫—Å–ø–æ–∑–∏—Ü–∏—è –ø–æ—Ä—Ç–∞
EXPOSE 8000

# –ó–∞–ø—É—Å–∫
ENTRYPOINT ["/app/entrypoint.sh"]
EOF

    print_success "–°–æ–∑–¥–∞–Ω –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π $dockerfile —Å –æ–±—Ä–∞–∑–æ–º $base_image"
}

fix_app_py() {
    print_info "–ü—Ä–æ–≤–µ—Ä–∫–∞ app.py –Ω–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å CPU/GPU..."
    
    if [ -f "app.py" ]; then
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
        backup_dockerfile "app.py"
        
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ device detection –≤ app.py
        sed -i 's/device="cuda"/device="cuda" if torch.cuda.is_available() else "cpu"/' app.py || true
        sed -i 's/compute_type="float16"/compute_type="float16" if torch.cuda.is_available() else "int8"/' app.py || true
        
        print_success "app.py –æ–±–Ω–æ–≤–ª–µ–Ω –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞"
    fi
}

test_fixed_image() {
    local dockerfile=$1
    print_info "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ Dockerfile..."
    
    # –ü–æ–ø—ã—Ç–∫–∞ —Å–±–æ—Ä–∫–∏ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º –∫—ç—à–µ–º
    if timeout 300 docker build -f "$dockerfile" --no-cache -t stenogramma-test . &> build.log; then
        print_success "–°–±–æ—Ä–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –æ–±—Ä–∞–∑–∞ —É—Å–ø–µ—à–Ω–∞"
        
        # –û—á–∏—Å—Ç–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –æ–±—Ä–∞–∑–∞
        docker rmi stenogramma-test &> /dev/null || true
        rm -f build.log
        return 0
    else
        print_error "–û—à–∏–±–∫–∞ —Å–±–æ—Ä–∫–∏ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –æ–±—Ä–∞–∑–∞"
        echo "–õ–æ–≥–∏ —Å–±–æ—Ä–∫–∏:"
        tail -20 build.log 2>/dev/null || echo "–õ–æ–≥–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"
        rm -f build.log
        return 1
    fi
}

show_fix_summary() {
    echo
    print_success "üéâ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!"
    echo
    echo -e "${GREEN}üìã –ß—Ç–æ –±—ã–ª–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ:${NC}"
    echo "   ‚Ä¢ –ë–∞–∑–æ–≤—ã–π –æ–±—Ä–∞–∑: $WORKING_IMAGE"
    echo "   ‚Ä¢ PyTorch –∏–Ω–¥–µ–∫—Å: $PYTORCH_INDEX"
    
    if [ "$IS_GPU_IMAGE" = true ]; then
        echo "   ‚Ä¢ –¢–∏–ø: GPU –æ–±—Ä–∞–∑"
        echo "   ‚Ä¢ Dockerfile: –æ–±–Ω–æ–≤–ª–µ–Ω –¥–ª—è GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∏"
        if [ -f "Dockerfile.cpu" ]; then
            echo "   ‚Ä¢ Dockerfile.cpu: —Å–æ–∑–¥–∞–Ω –∫–∞–∫ fallback"
        fi
    else
        echo "   ‚Ä¢ –¢–∏–ø: CPU fallback –æ–±—Ä–∞–∑"
        echo "   ‚Ä¢ Dockerfile.cpu: —Å–æ–∑–¥–∞–Ω –¥–ª—è CPU —Ä–µ–∂–∏–º–∞"
    fi
    
    echo
    echo -e "${BLUE}üöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:${NC}"
    echo "1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è:"
    echo "   git diff Dockerfile*"
    echo
    echo "2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–±–æ—Ä–∫—É:"
    if [ "$IS_GPU_IMAGE" = true ]; then
        echo "   ./build_docker.sh --gpu"
    else
        echo "   ./build_docker.sh --cpu"
    fi
    echo
    echo "3. –ü—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –æ–±—Ä–∞–∑:"
    if [ "$IS_GPU_IMAGE" = true ]; then
        echo "   ./build_docker.sh --cpu"
    else
        echo "   # –ò—Å–ø—Ä–∞–≤—å—Ç–µ NVIDIA –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ:"
        echo "   ./build_docker.sh --gpu"
    fi
    echo
    echo -e "${RED}‚ö†Ô∏è  –í–∞–∂–Ω–æ:${NC}"
    echo "   ‚Ä¢ –†–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏ —Å–æ–∑–¥–∞–Ω—ã —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .backup.*"
    echo "   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å PyTorch –≤–µ—Ä—Å–∏–∏ —Å –≤–∞—à–∏–º CUDA"
    echo "   ‚Ä¢ –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è GPU –æ–±—Ä–∞–∑"
}

main() {
    print_header
    
    print_info "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º —Å Docker –æ–±—Ä–∞–∑–∞–º–∏..."
    echo
    
    check_docker
    
    if ! find_working_cuda_image; then
        print_error "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ä–∞–±–æ—á–∏–π –æ–±—Ä–∞–∑!"
        exit 1
    fi
    
    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ Dockerfile
    if [ "$IS_GPU_IMAGE" = true ]; then
        create_fixed_dockerfile "Dockerfile" "$WORKING_IMAGE" "$PYTORCH_INDEX" true
        
        # –°–æ–∑–¥–∞–Ω–∏–µ CPU fallback
        for cpu_image in "ubuntu:22.04" "ubuntu:20.04"; do
            if test_base_image "$cpu_image"; then
                create_fixed_dockerfile "Dockerfile.cpu" "$cpu_image" "cpu" false
                break
            fi
        done
    else
        # –¢–æ–ª—å–∫–æ CPU –≤–µ—Ä—Å–∏—è
        create_fixed_dockerfile "Dockerfile.cpu" "$WORKING_IMAGE" "$PYTORCH_INDEX" false
        
        # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ GPU Dockerfile –µ—Å–ª–∏ –æ–Ω –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π
        if [ -f "Dockerfile" ]; then
            backup_dockerfile "Dockerfile"
            rm -f "Dockerfile"
            print_info "–£–¥–∞–ª–µ–Ω –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π GPU Dockerfile"
        fi
    fi
    
    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ app.py
    fix_app_py
    
    # –¢–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –æ–±—Ä–∞–∑–∞
    if [ "$IS_GPU_IMAGE" = true ] && [ -f "Dockerfile" ]; then
        test_fixed_image "Dockerfile"
    elif [ -f "Dockerfile.cpu" ]; then
        test_fixed_image "Dockerfile.cpu"
    fi
    
    show_fix_summary
}

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∏–∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
if [ ! -f "app.py" ] || [ ! -f "crypto_utils.py" ]; then
    print_error "–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –∏–∑ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞ Stenogramma"
    exit 1
fi

main